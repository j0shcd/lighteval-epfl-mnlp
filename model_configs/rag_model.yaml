model:
  base_params:
    # Change this to your own model name on huggingface hub
    model_args: "pretrained=Qwen/Qwen3-0.6B,revision=main"

    # (Optional) If you want to use a chat template, set "use_chat_template" to true.
    # (Optional) However, you must ensure that the chat template is saved in the model checkpoint.
    use_chat_template: true
    
    dtype: "float16"
    compile: false
  rag_params:
    embedding_model: "thenlper/gte-small" # Change this to your own embedding model name on huggingface hub
    docs_name_or_path: "m-ric/huggingface_doc" # Change this to your own document name or path on huggingface hub
    similarity_fn: cosine # Select the similarity function to use, options are: cosine, dot_product, max_inner_product, jaccard
    top_k: 20 # Choose the number of documents to retrieve
    num_chunks: 100000 # This is the limit we set for the number of chunks to retrieve from the document where each chunk is 512 tokens
    faiss_index_path: "./faiss_cache/my_index.index"

  # Ignore this section, do not modify!
  merged_weights:
    delta_weights: false
    adapter_weights: false
    base_model: null
  generation:
    temperature: 0.0
